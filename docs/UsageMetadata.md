# GeminiSharp.Model.UsageMetadata

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**PromptTokenCount** | **int** | Number of tokens in the prompt | [optional] 
**CandidatesTokenCount** | **int** | Total number of tokens across all the generated response candidates | [optional] 
**TotalTokenCount** | **int** | Total token count for the generation request (prompt + response candidates) | [optional] 
**CachedContentTokenCount** | **int** | Number of tokens in the cached part of the prompt | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)

